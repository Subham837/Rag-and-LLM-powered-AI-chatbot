<h1 align="center">AI Tutor â€“ RAG & LLM Powered Chatbot</h1>

<p align="center">
  A document-aware AI tutor built using <b>Retrieval-Augmented Generation (RAG)</b> and
  <b>Large Language Models (LLMs)</b> for accurate, context-grounded question answering.
</p>

<hr/>

<h2>ğŸ“Œ Project Description</h2>

<p>
This project implements an <b>AI Tutor</b> that allows users to upload PDF documents and ask
natural language questions. Instead of relying solely on an LLMâ€™s internal knowledge,
the system retrieves relevant information from the document and generates answers
strictly grounded in that content.
</p>

<p>
The architecture significantly reduces hallucinations and makes the chatbot suitable
for educational, research, and enterprise document-based use cases.
</p>

<hr/>

<h2>âœ¨ Key Capabilities</h2>

<ul>
  <li>PDF-based question answering</li>
  <li>Retrieval-Augmented Generation (RAG) pipeline</li>
  <li>LLM-powered reasoning and response generation</li>
  <li>Multi-tool extensible design</li>
  <li>Thread-based conversational sessions</li>
  <li>Clean and interactive Streamlit UI</li>
</ul>

<hr/>

<h2>ğŸ§  System Workflow</h2>

<pre>
PDF Upload
   â†’ Document Chunking
   â†’ Embeddings Generation
   â†’ Vector Retrieval (RAG)
   â†’ LLM Reasoning
   â†’ Context-Aware Answer
</pre>

<hr/>

<h2>ğŸ› ï¸ Technology Stack</h2>

<table>
  <tr>
    <th align="left">Layer</th>
    <th align="left">Technology</th>
  </tr>
  <tr>
    <td>Language</td>
    <td>Python</td>
  </tr>
  <tr>
    <td>Frontend</td>
    <td>Streamlit</td>
  </tr>
  <tr>
    <td>LLMs</td>
    <td>OpenAI / Gemini / Hugging Face (pluggable)</td>
  </tr>
  <tr>
    <td>Retrieval</td>
    <td>Embeddings + Vector Store</td>
  </tr>
  <tr>
    <td>Architecture</td>
    <td>Modular & Scalable</td>
  </tr>
</table>

<hr/>

<h2>ğŸ“‚ Project Structure</h2>

<pre>
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ingest_pdf.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ llm_handler.py
â”‚   â””â”€â”€ tools.py
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ data/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
</pre>

<hr/>

<h2>ğŸš€ Running the Application</h2>

<pre>
git clone https://github.com/Subham837/Rag-and-LLM-powered-AI-chatbot.git
cd Rag-and-LLM-powered-AI-chatbot

python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install -r requirements.txt
streamlit run app.py
</pre>

<hr/>

<h2>ğŸ¯ Use Cases</h2>

<ul>
  <li>AI-powered tutoring systems</li>
  <li>PDF and document-based assistants</li>
  <li>Enterprise knowledge-base chatbots</li>
  <li>Academic and research RAG experiments</li>
</ul>

<hr/>

<h2>ğŸ‘¤ Author</h2>

<p>
<b>Subham Pradhan</b><br/>
Machine Learning & AI Enthusiast<br/>
GitHub: <a href="https://github.com/Subham837">https://github.com/Subham837</a>
</p>

<hr/>

<p align="center">
â­ If you find this project useful, consider starring the repository.
</p>
